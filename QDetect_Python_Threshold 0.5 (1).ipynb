{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680708e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import KFold\n",
    "from qiskit import BasicAer\n",
    "#from qiskit.aqua import QuantumInstance\n",
    "#from qiskit.aqua.algorithms import QSVM\n",
    "#from qiskit.aqua.components.multiclass_extensions import (ErrorCorrectingCode, AllPairs, OneAgainstRest)\n",
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "from qiskit.utils import algorithm_globals\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c3b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def chisqr_featselection(F, L, m):\n",
    "    \"\"\"\n",
    "    Select top m features using chi-squared test.\n",
    "    Parameters:\n",
    "        F: numpy array or sparse matrix, shape=(n_samples, n_features)\n",
    "            Feature matrix.\n",
    "        L: numpy array, shape=(n_samples,)\n",
    "            Labels for each example in F.\n",
    "        m: int\n",
    "            Number of features to select.\n",
    "    Returns:\n",
    "        topFeatures: numpy array, shape=(n_features,)\n",
    "            Binary vector indicating which features are selected (1) or not (0).\n",
    "    \"\"\"\n",
    "    # convert F to a sparse matrix\n",
    "    F = csr_matrix(F)\n",
    "\n",
    "    # total number of examples\n",
    "    n = len(L)\n",
    "\n",
    "    # number of examples with the category\n",
    "    p = np.sum(L > 0)\n",
    "\n",
    "    # number of examples without the category\n",
    "    q = n - p\n",
    "\n",
    "    # compute the chi-square score for each feature\n",
    "    chi2 = np.zeros(F.shape[1])\n",
    "    for i in range(F.shape[1]):\n",
    "        # number of examples with the feature and the category\n",
    "        a = np.sum(F[L > 0][:, i])\n",
    "        \n",
    "        # number of examples with the feature but not the category\n",
    "        b = np.sum(F[L == 0][:, i])\n",
    "        \n",
    "        # number of examples without the feature but with the category\n",
    "        c = p - a\n",
    "        \n",
    "        # number of examples without the feature and without the category\n",
    "        d = q - b\n",
    "        \n",
    "        # chi-square score\n",
    "        #chi2[i] = (n * (a*d-b*c) * (a*d + b*c - (n * (a + b) * (c + d)))**2) / ((a + b) * (c + d) * (a + c) * (b + d))\n",
    "        chi2[i] = (n * (a*d - b*c)) / ((a + b) * (a + c) * (b + d) * (c + d))\n",
    "\n",
    "     #get the indices of the top m features\n",
    "    topFeatures = np.zeros(F.shape[1])\n",
    "    topFeatures[np.argsort(chi2)[::-1][:m]] = 1\n",
    "\n",
    "    return topFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257ee145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load data\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# Convert text to features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "trainingSet = vectorizer.fit_transform(newsgroups_train.data)\n",
    "testSet = vectorizer.transform(newsgroups_test.data)\n",
    "fea = vectorizer.fit_transform(newsgroups.data)\n",
    "gnd = np.array(newsgroups.target)\n",
    "# Convert topic labels to integers\n",
    "trainTopic = newsgroups_train.target\n",
    "testTopic = newsgroups_test.target\n",
    "\n",
    "\n",
    "em_nb_list = []\n",
    "em_svm_list = []\n",
    "em_cknn_list = []\n",
    "em_dt_list = []\n",
    "em_list = []\n",
    "\n",
    "all_topics = np.zeros((20,))\n",
    "for i in range(20):\n",
    "    all_topics[i] = np.sum(trainTopic == i)\n",
    "topics = np.where(all_topics > 0)[0]\n",
    "\n",
    "times_qdetect = []\n",
    "times_dt = []\n",
    "times_nb = []\n",
    "times_knn = []\n",
    "times_svm = []\n",
    "\n",
    "for topic in topics:\n",
    "    trainTopic_topic = (trainTopic == topic)\n",
    "    # Chi-square feature selection method\n",
    "    top_features = chi2(trainingSet, trainTopic_topic)[1]\n",
    "    top_features_idx = np.argsort(top_features)[-100:]\n",
    "\n",
    "    top_features = top_features[top_features_idx]\n",
    "\n",
    "    featsIdx = np.nonzero(top_features)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96f98e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11314,),\n",
       " (7532,),\n",
       " (11314, 5000),\n",
       " (7532, 5000),\n",
       " (18846, 5000),\n",
       " (18846,),\n",
       " (100,),\n",
       " (),\n",
       " (20,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTopic.shape ,testTopic.shape , trainingSet.shape , testSet.shape ,fea.shape ,gnd.shape ,featsIdx.shape ,topic.shape ,topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9db0ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_measures(testLabel, yfit):\n",
    "    idx = (testLabel==1)\n",
    "    p = len(testLabel[idx])\n",
    "    n = len(testLabel[~idx])\n",
    "    N = p+n\n",
    "\n",
    "    tp = sum(testLabel[idx]==yfit[idx])\n",
    "    #tp = sum(testLabel[idx]==yfit[idx][0])\n",
    "    \n",
    "\n",
    "    tn = sum(testLabel[~idx]==yfit[~idx])\n",
    "    fp = n-tn\n",
    "    fn = p-tp\n",
    "\n",
    "    accuracy = (tp+tn)/N\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "\n",
    "    #recall = tp/(tp+fn)\n",
    "    f_measure = 2*((precision*recall)/(precision + recall))\n",
    "    print (accuracy, precision, recall, f_measure)\n",
    "    evaluation = [accuracy, precision, recall, f_measure]\n",
    "    return evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12734ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "def qdetect(trF, trL, teF, type):\n",
    "    # trF: training feature matrix\n",
    "    # trL: training labels\n",
    "    # teF: test feature matrix\n",
    "    # type: type of representation\n",
    "    \n",
    "    trSetDim = trF.shape\n",
    "    \n",
    "    X = trF\n",
    "    \n",
    "    N = trSetDim[0]    # number of documents in the training set\n",
    "    k = trSetDim[1]    # number of features\n",
    "    r = trL       # labels\n",
    "    \n",
    "    # compute probability p's (in category)\n",
    "    R=sum(r)       # total number of documents in category\n",
    "    p=np.zeros(k)\n",
    "    for j in range(k):\n",
    "        p[j]=0\n",
    "        #p[j]=(sum(np.sign(X[0:N,j])*(r[0:N]))+0.5)/ (R+1)\n",
    "        p[j] = (np.all(np.sign(X[0:N, j].toarray().flatten()) * r[0:N]) + 0.5) / (R + 1)\n",
    "    if(sum(p)>0):\n",
    "        p=np.sqrt(p/sum(p))\n",
    "    \n",
    "    # compute probability q's (not in category)\n",
    "    q=np.zeros(k)\n",
    "    for j in range(k):\n",
    "        q[j]=0\n",
    "        #q[j]=(sum(np.sign(X[0:N,j])*(1-r[0:N]))+0.5)/(sum(1-r[0:N])+1)\n",
    "        q[j] = (np.all(np.sign(X[0:N, j].toarray().flatten()) * (1 - r[0:N])) + 0.5) / (np.sum(1 - r[0:N]) + 1)\n",
    "    if(sum(q)>0):\n",
    "        q=np.sqrt(q/sum(q))\n",
    "    print(p.shape)\n",
    "    print(q.shape)\n",
    "    print(trF.shape)\n",
    "    print(trL.shape)\n",
    "    print(teF.shape)\n",
    "    if k > 2 and np.isreal(q).all() and np.isreal(p).all() and np.isnan(p).sum() == 0 and np.isnan(q).sum() == 0:\n",
    "        if type == 1:\n",
    "         # eigendecomposition step where it allows obtaining diagonal matrix containing eigenvalues on the main diagonal, and another matrix whose columns are the corresponding eigenvectors      \n",
    "            #[UB, sB] = scipy.sparse.linalg.eigs(np.matmul(p.T, p) - np.matmul(q.T, q), k - 2)\n",
    "            [UB, sB] = scipy.sparse.linalg.eigs(p.T @ p - q.T @ q, k - 2)\n",
    "            \n",
    "            if sB[0] > 0:\n",
    "                eigB1 = UB[:, 0]\n",
    "                eigB0 = UB[:, 0:k-2]\n",
    "            else:\n",
    "                eigB1 = UB[:, 0:k-2]\n",
    "                eigB0 = UB[:, 0]\n",
    "    print(eigB1.shape)           \n",
    "         # Prediction step\n",
    "    predictions = np.zeros((teF.shape[0], 1))\n",
    "    s1 = np.zeros((teF.shape[0], 1))\n",
    "    s0 = np.zeros((teF.shape[0], 1))\n",
    "    \n",
    "\n",
    "    for j in range(teF.shape[0]):\n",
    "        #s1[j] = np.trace(np.matmul(np.matmul(teF[j,:], np.matmul(eigB1, eigB1.T)), teF[j,:].T))\n",
    "        s1[j, 0] = np.trace(np.matmul(np.matmul(teF[j, :], eigB1), np.matmul(eigB1.T, teF[j, :].T)))\n",
    "         \n",
    "        if s1[j, 0] > 0.5:\n",
    "            predictions[j, 0] = 1\n",
    "            \n",
    "            P = predictions\n",
    "    else:\n",
    "        P = np.full((teF.shape[0], 1), np.nan)\n",
    "    return P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3930918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "774f8296",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13592\\368415187.py:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp/(tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9576473712161444 nan 0.0 nan\n",
      "0.0001327668613913967 0.0001386193512614361 0.0031347962382435317 0.00026549847338377453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13592\\368415187.py:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp/(tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9576473712161444 nan 0.0 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13592\\368415187.py:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp/(tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9576473712161444 nan 0.0 nan\n",
      "(100,)\n",
      "(100,)\n",
      "(11314, 100)\n",
      "(11314,)\n",
      "(7532, 100)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13592\\1523145490.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m# Classification with Quantum Detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m#p = qdetect(trS, trainTopic, teS, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrainTopic\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mteS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;31m#np.where(trainTopic==topic, 1, -1).any()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13592\\1560759330.py\u001b[0m in \u001b[0;36mqdetect\u001b[1;34m(trF, trL, teF, type)\u001b[0m\n\u001b[0;32m     43\u001b[0m          \u001b[1;31m# eigendecomposition step where it allows obtaining diagonal matrix containing eigenvalues on the main diagonal, and another matrix whose columns are the corresponding eigenvectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m#[UB, sB] = scipy.sparse.linalg.eigs(np.matmul(p.T, p) - np.matmul(q.T, q), k - 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;33m[\u001b[0m\u001b[0mUB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msB\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meigs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\anaconda\\lib\\site-packages\\scipy\\sparse\\linalg\\_eigen\\arpack\\arpack.py\u001b[0m in \u001b[0;36meigs\u001b[1;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, OPpart)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \"\"\"\n\u001b[1;32m-> 1249\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'expected square matrix (shape=%s)'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(topics):\n",
    "    \n",
    "    \n",
    "    # Chi-square feature selection method\n",
    "    \n",
    "    topFeatures = chisqr_featselection(trainingSet, trainTopic, 100)\n",
    "    featsIdx = np.where(topFeatures > 0)[0]\n",
    "\n",
    "    # Naive Bayes with feature selection\n",
    "    nb = MultinomialNB()\n",
    "    #nb.fit(trainingSet[:, featsIdx], trainTopic == topic)\n",
    "    nb.fit(trainingSet[:, featsIdx], (trainTopic == topic).ravel())\n",
    "\n",
    "    label = nb.predict(testSet[:, featsIdx])\n",
    "    em_ns = eval_measures(testTopic == topic, label)\n",
    "    em_nb_list.append(em_ns)\n",
    "    import timeit\n",
    "    #times_nb[i] = timeit.timeit(lambda: nb.predict(testSet[:, featsIdx]), number=1)\n",
    "    times_nb.append(timeit.timeit(lambda: nb.predict(testSet[:, featsIdx]), number=1))\n",
    "\n",
    "    # SVM with feature selection\n",
    "    svm = SVC(kernel='linear')\n",
    "    #svm.fit(trainingSet, trainTopic )\n",
    "    svm.fit(trainingSet[:, featsIdx], trainTopic)\n",
    "    label = svm.predict(testSet[:, featsIdx])\n",
    "    em_ss = eval_measures(testTopic == topic, label)\n",
    "    em_svm_list.append(em_ss)\n",
    "    times_svm.append(timeit.timeit(lambda: svm.predict(testSet[:, featsIdx]), number=1))\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    # KNN with feature selection\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(trainingSet[:, featsIdx], trainTopic == topic)\n",
    "    label = knn.predict(testSet[:, featsIdx])\n",
    "    em_ks = eval_measures(testTopic == topic, label)\n",
    "    em_cknn_list.append(em_ks)\n",
    "    times_knn.append(timeit.timeit(lambda: knn.predict(testSet[:, featsIdx]), number=1))\n",
    "    \n",
    "\n",
    "   \n",
    "   \n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "    #Decision Tree with feature selection\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(trainingSet[:, featsIdx], trainTopic == topic)\n",
    "    label = dt.predict(testSet[:, featsIdx])\n",
    "    em_ds = eval_measures(testTopic == topic, label)\n",
    "    em_dt_list.append(em_ds)\n",
    "    times_dt.append(timeit.timeit(lambda: dt.predict(testSet[:, featsIdx]), number=1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    #Binary Selection\n",
    "    \n",
    "    C = StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(trainingSet[:, featsIdx], trainTopic==i)\n",
    "    trS = trainingSet[:, featsIdx]\n",
    "    teS = testSet[:, featsIdx]\n",
    "    if len(featsIdx) > teS.shape[1]:\n",
    "        featsIdx = featsIdx[:teS.shape[1]]\n",
    "        teS = teS[:, featsIdx]\n",
    "    #teS = teS[:, featsIdx]\n",
    "    #teS = teS[:, featsIdx] if teS.shape[1] > len(featsIdx) else teS[:, featsIdx[:teS.shape[1]]]\n",
    "\n",
    "    \n",
    "\n",
    "    # Classification with Quantum Detection\n",
    "    #p = qdetect(trS, trainTopic, teS, 1)\n",
    "    p = qdetect(trS, (trainTopic==topic), teS, 1)\n",
    "    \n",
    "    #np.where(trainTopic==topic, 1, -1).any()\n",
    "\n",
    "    #p = qdetect(trS, np.where(trainTopic==topic, 1, -1).astype(bool), teS, 1)\n",
    "\n",
    "    em = eval_measures(testTopic==topic, p)\n",
    "    em_list.append(em)\n",
    "    times_qdetect.append(timeit.timeit())\n",
    "    \n",
    "    \n",
    "   # print(sum(times_qdetect))\n",
    "   \n",
    "    print(sum(times_nb))\n",
    "    print(sum(times_svm))\n",
    "    print(sum(times_knn))\n",
    "    print(sum(times_dt))\n",
    "    print(sum(times_qdetect))\n",
    "    \n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3c49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01117cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ceeb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99c0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fef0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580a1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13caab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
